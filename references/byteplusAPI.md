# Obtain and configure an API Key

To invoke models on the ModelArk platform, you must authenticate using an API Key. This guide provides step-by-step instructions on how to obtain an API Key from the console and configure it securely as an environment variable. Following these steps ensures proper authentication while protecting your key from exposure and unauthorized use.
`<span id="20bdcc68">`

## Obtain an API Key

1. Open and log in to [API Key Management](https://console.byteplus.com/ark/region:ark+ap-southeast-1/apiKey) page.
2. (Optional) Click the drop-down arrow under **Account All Resources** in the top-left corner to switch the project space.
3. Click the **Create API Key** button.
4. In the dialog, confirm or change the API Key name in the **Name** text box, then click Create.

On the [API Key Management](https://console.byteplus.com/ark/region:ark+ap-southeast-1/apiKey) page, view details of the newly created API Key in the **API Key list**.
`<span id="f1908ee9">`

## API Key configuration

To prevent security risks, configure the API Key in an environment variable instead of hardcoding it in your code. Hardcoding can expose the key if your code leaks, potentially leading to unauthorized quota consumption and additional costs.
See configuration methods: [Configure the API key in environment variables](/docs/ModelArk/1399008#4b62407d).
`<span id="64cf3cd0">`

## API usage

* API Key quota: a primary account supports creating 50 API Keys; if you need more quota, submit [Ticket](https://console.byteplus.com/workorder/create?step=2&SubProductID=P00001514) Apply.
* API Key access control: An API Key is created within a specific project and can only be used to access resources in that project(i.e., model services and applications). You can add restrictions on which Model IDs / inference endpoints the API Key can authenticate, or on which IP addresses can call this API Key.
  * Tip: when you switch project spaces to create an API Key, you can restrict it to be used only as the authentication credential for model services in the specified project space. If multiple users share your account, use this approach to isolate permissions.
  * Note: only endpoints within the specified project are accessible with the API Key; cross-project access is not supported. If you migrate an endpoint across projects, the original API Key can no longer be used for that endpoint.

# Base URL and authentication

ModelArk APIs fall into two categories: model invocation (data-plane APIs) and control-plane APIs for managing inference endpoints and other control and management tasks They use different authentication methods. The sections below describe authentication for ModelArk APIs
`<span id="28e0db57">`

## Concepts

* **Data-plane APIs**: interfaces that directly handle **business data transfer, real-time interaction, and user request handling**, focusing on the flow and processing of actual business data, and delivering the system’s core external service capabilities Both the Chat API and Responses API for invoking model services are data-plane APIs
* **Control-plane AP**I: interfaces for **system resource management, configuration control, and status Monitoring**, focusing on managing and scheduling the data plane and system resources, and serving as the control center that ensures stable system operations ModelArk’s management API Key and foundation model management are control-plane APIs
* **Base URL**: the base template for constructing full API request URLs. It includes **the scheme (for example, http/https), host (domain name or IP), port (optional), and base path (optional)**, and serves as the common prefix for all specific API paths You can compose a full API URL by appending the API path, version, and other parameters to the Base URL. Typical structure: `[scheme]://[host]/[base path (optional)]`

`<span id="b77a3928">`

## Base URL

Base URLs for each API type

* Data plane API:https://ark.ap-southeast.bytepluses.com/api/v3

`<span id="0fed4817">`

## Data plane API authentication

Supports two authentication methods: API key authentication (simple and convenient) and Access Key authentication (traditional cloud resource permission management; managed by resource groups, cloud products, and other dimensions; suitable for fine-grained enterprise management).
`<span id="60db1ed6">`

### API key

`<span id="6011c5a5">`

#### Prerequisites

* [Obtain an API key](https://console.byteplus.com/ark/apiKey)
* [Enable the model service](https://console.byteplus.com/ark/openManagement)
* In [Model List](/docs/ModelArk/1330310) obtain the required Model ID

`<span id="d44d13a6">`

#### Signature construction

Add the `Authorization` header to the HTTP request header as follows:

```Shell
Authorization: Bearer $ARK_API_KEY
```

`<span id="e8bd2618">`

#### Sample API call

```Shell
curl https://ark.ap-southeast.bytepluses.com/api/v3/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $ARK_API_KEY" \
  -d '{
    "model": "seed-1-6-250915",
    "messages": [
        {
            "role": "system",
            "content": "You are a helpful assistant."
        },
        {
            "role": "user",
            "content": "Hello!"
        }
    ]
  }'
```

* Replace the Model ID as needed. To query the Model ID, see [Model List](/docs/ModelArk/1330310).

`<span id="21bff83b">`

### Access key

`<span id="3ad1c414">`

#### Prerequisites

You have obtained the Access Key. To create or view an Access Key, see [API Access Key Management](https://console.byteplus.com/iam/keymanage).

> Because the primary account's Access Key has elevated permissions, create an IAM user, grant permissions such as ModelArk, then use the IAM user's Access Key to perform operations. For details, see [Access Control Using IAM](/docs/ModelArk/1263493) .

`<span id="d03b2bb1">`

#### Usage example

See [Use Access Key for authentication](/docs/undefined/6906ced5922904054fca577c#fa44b913).

> When using Access Key authentication, set the model field to the Endpoint ID.

`<span id="bdd329d5">`

## Control plane API authentication

Other APIs include control plane APIs for API key management, inference endpoint management, and more.
`<span id="50f355e8">`

### Access key

You have obtained the Access Key. To create or view an Access Key, see [API access key management](https://console.byteplus.com/iam/keymanage).
`<span id="c04e9b57">`

#### Method: use samples/documentation (simple, recommended)

See [OpenAPI Center](https://api.byteplus.com/api-explorer?action=GetApiKey&groupName=Manage%20API%20Key&serviceCode=ark&tab=3&tab_sdk=GO&version=2024-01-01).

# Install and upgrade SDK

ModelArk offers SDKs for Python, Go, and Java, enabling you to quickly integrate ModelArk’s model services into your existing tech stack.
`<span id="2708d57e">`

## Python SDK

`<span id="f2baa8aa">`

### Prerequisites

Python is installed locally, version 3.7 or later.

> You can verify the Python version in the terminal. If installation is needed, refer to the [Python installation guide](https://wiki.python.org/moin/BeginnersGuide/Download) and choose version 3.7 or later.

```Bash
python -V
```

`<span id="bb014324">`

### Install the Python SDK

Run the following command in the terminal to install the Python SDK.

```Bash
pip install byteplus-python-sdk-v2 
```

:::tip

* If local installation errors occur, try the following:
  * Run `pip install byteplus-python-sdk[ark]`
* If source code installation is needed, download and unzip the corresponding version of the SDK package, enter the directory and run: `python setup.py install --user`
  :::
  `<span id="d6b883b8">`

### Upgrade the Python SDK

To access ModelArk's latest capabilities, upgrade the SDK to the latest version.

```Bash
pip install byteplus-python-sdk-v2  -U
```

`<span id="f116fb9f">`

## Go SDK

`<span id="0fa8c2bc">`

### Prerequisites

Check the version of Go; it must be 1.18 or later.

```Bash
go version
```

If Go isn’t installed or the version is too old, visit the [official Go website](https://golang.google.cn/dl/) to download and install version 1.18 or later.
`<span id="ae8b42ab">`

### Install the Go SDK

1. The Go SDK is managed via go mod; run the following command to initialize go mod. Replace `<your-project-name>` with the actual project name.

```Bash
go mod init <your-project-name>
```

2. After initializing go mod locally, run the following command to install the latest SDK version.

```Bash
go get -u github.com/byteplus-sdk/byteplus-go-sdk-v2 
```

:::tip
If you need to install a specific SDK version, use the following command:
`go get -u github.com/byteplus-sdk/byteplus-go-sdk-v2@<VERSION>`
Replace `<VERSION>` with the actual version number. View available SDK versions at: https://github.com/byteplus-sdk/byteplus-go-sdk-v2/releases
:::

3. Import the SDK into your code.

```Go
import "github.com/byteplus-sdk/byteplus-go-sdk-v2/service/arkruntime"
```

4. After updating dependencies, use the following command to clean up unnecessary dependencies and organize the `go.mod` and `go.sum` files.

```Bash
go mod tidy
```

`<span id="f0739bb0">`

### Upgrade the Go SDK

Refer to Step 1 and 2 in the **Install the Go SDK** section to upgrade to the latest/specified SDK version.

* Upgrade to the latest version

```Bash
go get -u github.com/byteplus-sdk/byteplus-go-sdk-v2
```

* Upgrade to a specific version

```Bash
go get -u github.com/byteplus-sdk/byteplus-go-sdk-v2@<VERSION>
```

`<span id="e7ae2925">`

## Java SDK

`<span id="41f31f3c">`

### Applicability

This SDK supports Java server-side development only and does not currently support Android platforms. For Android, you need to implement your own integration.
`<span id="e3518e9f">`

### Prerequisites

1. Check the Java version; it must be 1.8 or later.

```Bash
java -version
```

If Java isn’t installed or the version is too old, visit the [official Oracle website](https://www.java.com/en/download/help/index_installing.html) to download and install version 1.8 or later.
`<span id="ae8db863">`

### Install the Java SDK

The ModelArk Java SDK can be installed using either Maven or Gradle.
`<span id="db12484d">`

#### Install via Maven

In `pom.xml`, add the following configuration. For the full setup, see [Maven Central](https://central.sonatype.com/artifact/com.byteplus/byteplus-java-sdk-v2-ark-runtime):

```XML
...
<dependency>
  <groupId>com.byteplus</groupId>
  <artifactId>byteplus-java-sdk-v2-ark-runtime</artifactId>
  <version>LATEST</version>
</dependency>
...
```

`<span id="4858e8c3">`

### Install via Gradle

In `build.gradle`, add the following configuration. Add the dependency to the `dependencies` section.

```Plain
implementation 'com.byteplus:byteplus-java-sdk-v2-ark-runtime:LATEST'
```

`<span id="4ab4182d">`

### Upgrade the Java SDK

:::tip
Get the SDK version information, replace 'LATEST' with a specific/latest version number. Version information can be found at: https://github.com/byteplus-sdk/byteplus-java-sdk-v2/releases
:::
Use the same methods described in the **Install the Java SDK** section to upgrade, replace 'LATEST' with a specific/latest version number.
`<span id="6f32c555">`

## Third-party SDKs

ModelArk's model invocation APIs are compatible with the OpenAI API protocol. You can use OpenAI-compatible multi-language community SDK to call ModelArk's models or applications. It's easy to migrate your services to the ModelArk platform and the Seed model family. For details, see [Compatible with OpenAI API](/docs/ModelArk/1330626).
`<span id="4b8511f6">`

## See also

[Common SDK usage examples](/docs/ModelArk/1544136)

# Creating a video generation task

`POST https://ark.ap-southeast.bytepluses.com/api/v3/contents/generations/tasks`[Try](https://api.byteplus.com/api-explorer/?action=CreateContentsGenerationsTasks&groupName=Video%20Generation%20API&serviceCode=ark&version=2024-01-01)
This topic describes the request and response parameters of the API operation for creating a video generation task. You can refer to this topic for the meaning of a parameter when you call this API operation. After the specified model generates a video based on the input image and text information, you can query the video generation task by condition and obtain the generated video.

`<span id="hfIqUF5g">`

### The video generation capabilities supported by different models are as follows:

* **Seedance 1.5 pro==^new^==** ** ** **==^Video with Audio^==** ** (Configurable)**
  * **Image\-to\-Video\-First Frame and Last Frame: ** Generate the target video based on your ++first\-frame image++ +  ++last\-frame image++ + ++text prompt (optional)++  + ++parameters (optional)++ .
  * **Image\-to\-Video\-First Frame:**  Generate the target video based on your ++first\-frame image++ + ++text prompt (optional)++  + ++parameters (optional)++ .
  * **Text\-to\-Video: ** Generate the target video based on your ++text prompt++ + ++parameters (optional)++ .
* **Seedance 1.0 pro**
  * **Image\-to\-Video\-First Frame and Last Frame: ** Generate the target video based on your ++first\-frame image++ +  ++last\-frame image++ + ++text prompt (optional)++  + ++parameters (optional)++ .
  * **Image\-to\-Video\-First Frame:**  Generate the target video based on your ++first\-frame image++ + ++text prompt (optional)++  + ++parameters (optional)++ .
  * **Text\-to\-Video: ** Generate the target video based on your ++text prompt++ + ++parameters (optional)++ .
* **seedance\-pro\-fast**
  * **Image\-to\-Video\-First Frame:**  Generate the target video based on your ++first\-frame image++ + ++text prompt (optional)++  + ++parameters (optional)++ .
  * **Text\-to\-Video: ** Generate the target video based on your ++text prompt++ + ++parameters (optional)++ .
* **Seedance 1.0 lite**
  * **seedance\-1\-0\-lite\-t2v：**  Text\-to\-Video. Generate the target video based on your ++text prompt++ + ++parameters (optional)++ .
  * **seedance\-1\-0\-lite\-i2v：** Image\-to\-Video.
    * **Image\-to\-Video\-Reference Images: ** Generate the target video based on your ++reference images（1\-4 images）++  + ++text prompt (optional)++  + ++parameters (optional)++ .
    * **Image\-to\-Video\-First Frame and Last Frame: ** Generate the target video based on your ++first\-frame image++ +  ++last\-frame image++ + ++text prompt (optional)++  + ++parameters (optional)++ .
    * **Image\-to\-Video\-First Frame:**  Generate the target video based on your ++first\-frame image++ + ++text prompt (optional)++  + ++parameters (optional)++ .

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Try" key="cKmdyIjR"><RenderMd content={`<APILink link="https://api.byteplus.com/api-explorer/?action=CreateContentsGenerationsTasks&groupName=Video%20Generation%20API&serviceCode=ark&version=2024-01-01" description="API Explorer 您可以通过 API Explorer 在线发起调用，无需关注签名生成过程，快速获取调用结果。"></APILink>
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Quick start" key="uFBWUXquwX"><RenderMd content={` [ ](#)[Experience Center](https://console.byteplus.com/ark/region:ark+ap-southeast-1/experience/vision)  <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_2abecd05ca2779567c6d32f0ddc7874d.png =20x) </span>[Model List](https://docs.byteplus.com/en/docs/ModelArk/1330310) <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_a5fdd3028d35cc512a10bd71b982b6eb.png =20x) </span>[Model Billing](https://docs.byteplus.com/en/docs/ModelArk/1099320#video-generation) <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_afbcf38bdec05c05089d5de5c3fd8fc8.png =20x) </span>[API Key](https://console.byteplus.com/ark/region:ark+ap-southeast-1/apiKey?apikey=%7B%7D)
 <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_57d0bca8e0d122ab1191b40101b5df75.png =20x) </span>[API Call Guide](https://docs.byteplus.com/en/docs/ModelArk/1366799) <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_f45b5cd5863d1eed3bc3c81b9af54407.png =20x) </span>[ API Reference](https://docs.byteplus.com/en/docs/ModelArk/Video_Generation_API) <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_1609c71a747f84df24be1e6421ce58f0.png =20x) </span>[FAQs](https://docs.byteplus.com/en/docs/ModelArk/1359411) <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_bef4bc3de3535ee19d0c5d6c37b0ffdd.png =20x) </span>[Model Activation](https://console.byteplus.com/ark/region:ark+ap-southeast-1/openManagement?LLM=%7B%7D&tab=ComputerVision)
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Authentication" key="TiKNY18nXc"><RenderMd content={`This interface only supports API Key authentication. Please obtain a long\\-term API Key on the [ API Key management](https://console.byteplus.com/ark/region:ark+ap-southeast-1/apiKey?apikey=%7B%7D) page.
`}></RenderMd></Tabs.TabPane></Tabs>);
```

`<span id="RxN8G2nH">`

## Request parameters

> Jump to [Response parameters](#L9tzcCyD)

---

`<span id="BJ5XLFqM">`

### Request body

**model** `string` `Required`
The ID of the model that you want to call. You can [activate a model service](https://console.byteplus.com/ark/region:ark+ap-southeast-1/openManagement?LLM=%7B%7D&tab=ComputerVision) and [query the model ID](https://docs.byteplus.com/en/docs/ModelArk/1330310).
You can also use an endpoint ID to call a model, querying its rate limits, billing method (prepaid or postpaid), and status, and using its advanced capabilities such as monitoring and security. For more information, refer to [Obtaining an endpoint ID](https://docs.byteplus.com/en/docs/ModelArk/1099522).

---

**content** `object[]` `Required`
The information provided to the model for video generation; supports **text information**, **image information**, and **sample video information**. The supported combination formats are as follows:

* **Text only**: Generate a standard video based on the text prompt.
* **Text + Image**: Generate a standard video based on the text prompt and image.
* **Sample video==^new^==**: Generate a standard high\-quality video based on a successfully generated Draft video.

I**nformation type**

---

**Text information** `object`
The input text information for the model to generate a video.

Attributes

---

content.**type ** `string` `Required`
The type of the input content. In this case, set the value to `text`.

---

content.**text ** `string` `Required`
The input text information for the model, which describes the video to be generated. The content includes:

* **Text prompt (required)** : You can use Chinese and English characters. For tips on using prompts, please refer to [Guide to Seedance Prompts](https://docs.byteplus.com/en/docs/ModelArk/1587797).
* **Parameters (optional)** : You can add \-\-[parameters] after the text prompt to control the specifications of the output video. For more information, refer to **Text commands for models (optional)** .

---

**Image information** `object`
The input image information for the model to generate a video.

Attributes

---

content.**type ** `string` `Required`
The type of the input content. In this case, set the value to `image_url`. Supports image URL or image Base64 encoding.

---

content.**image_url ** `object` `Required`
The input image object for the model.

Attributes
content.image_url.**url ** `string` `Required`
The image information, which can be an image URL or the Base64\-encoded content of an image.

* Image URL: Make sure that the image URL is accessible.
* Base64\-encoded content: The format must be `data:image/<image format>;base64,<Base64-encoded content of the image>`,  noting that <image format\> should be in lowercase, such as `data:image/png;base64,<Base64-encoded content of the image`

:::tip Instructions
An input image must meet the following requirements:

* It must be in one of the following formats: JPEG, PNG, WebP, BMP, TIFF, GIF.  For Seedance 1.5 Pro, HEIC and HEIF formats are newly supported.
* Its aspect ratio must be in the range of 0.4 to 2.5.
* Its shorter side must be greater than 300 pixels, and its longer side must be less than 6,000 pixels.
* It must be smaller than 30 MB in size.

:::
content.**role ** `string` `Required under certain conditions`
The location or purpose of the image. Valid values:
:::warning warning
**Image\-to\-Video\-First Frame, ** **Image\-to\-Video\-First and Last Frames and Image\-to\-Video\-Reference Images ** are three mutually exclusive scenarios, and mixed use is not supported.

:::
**Image\-to\-Video\-First Frame**

* **Supported models：** Seedance 1.5 pro、Seedance 1.0 pro、Seedance 1.0 pro fast、Seedance 1.0 lite i2v
* **The value for the ** **role** **：** One `image_url` object must be provided. The `role` is optional. If provided, the value must be `first_frame`

**Image\-to\-Video\-First and Last Frames**

* **Supported model：** Seedance 1.5 pro、Seedance 1.0 pro、Seedance 1.0 lite i2v
* **The value for the ** **role** **：** Two image_url objects must be provided.The `role` is required.
  * The first image must have role set to `first_frame`
  * The second image must have role set to `last_frame`

:::tip Instructions
The first and last frame images provided can be the same. If the aspect ratios of the first and last frame images differ, the first frame image will be used as the reference, and the last frame image will be automatically cropped to match.

:::

**Image\-to\-Video \- Reference Images**

* **Supported model：** seedance\-1\-0\-lite\-i2v
* **The value for the ** **role** **：** One to four `image_url` objects must be provided. The `role` is required.
  * The role value for each reference image must be `reference_image`.

:::tip Instructions
For reference image\-based video generation, text prompts can be written in natural language to specify combinations of multiple images. However, for better instruction adherence, it is recommended to use the format: `[Image 1]xxx, [Image 2]xxx` to explicitly reference each image.
**Ex. 1**
A boy wearing glasses and a blue T\-shirt and a corgi dog, sitting on the lawn, in 3D cartoon style.
**Ex. 2 **
A boy wearing glasses and a blue T\-shirt from [Image 1] and a corgi dog from [Image 2], sitting on the lawn from [Image 3], in 3D cartoon style

:::

---

**Sample video information==^new^==** ** **  `object`
Generate an official video based on the sample task ID. This feature is only supported by **Seedance 1.5 Pro**. To learn more about how to use the Draft feature and review important notes, see [Draft sample mode](https://docs.byteplus.com/en/docs/ModelArk/1366799?lang=en#draft-sample-mode%E3%80%90new%E3%80%91).

Attributes
content.**type ** `string` %%require%%
The type of the input content; fixed to `draft_task`.

---

content.**draft_task** ** ** `object` %%require%%
The sample video task provided to the model.

Attributes
content.draft_task.**id ** `string` %%require%%
Sample Task ID. The platform will automatically reuse the user inputs applied by the Draft video (including **model**, content.**text**, content.**image_url**, **generate_audio**, **seed**, **ratio**, **duration**, **frames**, **camera_fixed**) to generate the official video.
For other parameters, you can specify custom values; if not specified, the default values of the current model will be applied.
The workflow consists of two steps:
**Step 1**: Call this API to generate a Draft video.
**Step 2**: If the Draft video meets your expectations, call this API again with the Draft video task ID returned in Step 1 to generate the final video. See [Draft sample mode](https://docs.byteplus.com/en/docs/ModelArk/1366799?lang=en#draft-sample-mode%E3%80%90new%E3%80%91) for detailed tutorials.

---

**callback_url** `string`
Please fill in the callback notification address for the result of this generation task. When there is a status change in the video generation task, Ark will send a callback request containing the latest task status to this address.
The content structure of the callback request is consistent with the response body of [Querying the information about a video generation task](https://docs.byteplus.com/en/docs/ModelArk/Querying_the_information_about_a_video_generation_task).
The status returned by the callback includes the following states:

* queued: In the queue.
* running: The task is running.
* succeeded: The task is successful. (If the sending fails, that is, the information of successful sending is not received within 5 seconds, the callback will be made three times)
* failed: The task fails. (If the sending fails, that is, the information of successful sending is not received within 5 seconds, the callback will be made three times)
* expired：The task has timed out. This occurs when the task has remained in the `running` or `queued` status for longer than the allowed expiration duration. The expiration duration can be set via the **execution_expires_after** field.

---

**return_last_frame** `Boolean` `Default value: false`

* **true**：Returns the last frame image of the generated video. After setting this parameter to `true`, you can obtain the last frame image by calling the [Querying the information about a video generation task](https://docs.byteplus.com/en/docs/ModelArk/Querying_the_information_about_a_video_generation_task). The last frame image is in PNG format, with its pixel width and height consistent with those of the generated video, and it contains no watermarks.
  Using this parameter allows the generation of multiple consecutive videos: the last frame of the previously generated video is used as the first frame of the next video task, enabling quick generation of multiple consecutive videos. For specific calling examples, please refer to [the tutorial](https://docs.byteplus.com/en/docs/ModelArk/1366799#generate-multiple-consecutive-videos).
* **false**：Does not return the last frame image of the generated video.

---

**service_tier** `string` `Default value: default`

> Modification to the service tier of submitted tasks is not supported.

Specifies the service tier for processing the current request.

* **default**: Online inference mode. This tier has lower RPM and concurrency quotas (see [Model List](https://docs.byteplus.com/en/docs/ModelArk/1330310)), suitable for latency\-sensitive inference scenarios.
* **flex**: Offline inference mode. This tier provides a higher TPD quota (see [Model List](https://docs.byteplus.com/en/docs/ModelArk/1330310)) at 50% of the price of the online inference tier, suitable for scenarios where low inference latency is not a critical requirement.

---

**execution_expires_after ** `integer` `Default value: 172800`
The task expiration threshold. Specifies the time (in seconds) after which a submitted task will expire, calculated from its **created_at** timestamp.

* **Default:**  172800 seconds (48 hours)
* **Valid Range:**  [3600，259200]

Regardless of the chosen **service_tier**, it is recommended to set an appropriate value based on your business scenario. Tasks exceeding the threshold will be automatically terminated and marked as `expired`.

---

**generate_audio==^new^==** ** ** `boolean` `Default: true`

> Only supported by Seedance 1.5 pro

Whether the generated video includes audio synchronized with the visuals.

* `true`: The model outputs a video with synchronized audio.
  Seedance 1.5 pro can automatically generate matching voice, sound effects, or background music based on the prompt and visual content. It is recommended to enclose dialogue in double quotes. Example: *A man stops a woman and says, "Remember, never point your finger at the moon."*
* `false`: The model outputs a silent video.

---

**draft==^new^==** ** ** `boolean` `Default: false`

> Only supported by Seedance 1.5 pro

Whether to enable the **Draft sample mode**. See [Draft sample mode](https://docs.byteplus.com/en/docs/ModelArk/1366799?lang=en#draft-sample-mode%E3%80%90new%E3%80%91) for tutorials and important notes.

* `true`: Enable the sample mode to generate a preview video. This allows you to quickly verify if the scene structure, shot scheduling, subject movements, and the alignment with the prompt intent meet expectations. It consumes fewer tokens than a standard video, resulting in lower usage costs.
* `false`: Disable the Draft sample mode to directly generate a standard video.

:::tip tip
When **Draft sample mode** is enabled, the system will generate a Draft video of 480p resolution (an error will be thrown if other resolutions are used). This mode does not support returning the last frame or offline inference.

:::
---

:::warning Upgrade Instructions for Partial Parameters
For the **resolution**, **ratio**, **duration**, **frames**, **seed**, **camera_fixed** and **watermark** parameters, ModelArk has introduced an updated method for passing parameters, as demonstrated below. The **Seedance 1.0/1.5** models still support the legacy method for backward compatibility.
Different models may support different parameters and value ranges. For details, please refer to [Output Video Format](https://docs.byteplus.com/en/docs/ModelArk/1366799#configure-video-output-specifications%E3%80%90new%E3%80%91). If the input parameters or values are not compatible with the selected model, the relevant content will be ignored or an error will be thrown.

* **New method: Pass the paramters directly** **in the request body.**  This method uses strict validation—if a parameter is incorrect, the model will return an error prompt.
* **Legacy method: Append \-\-[parameter] after the text prompt. ** This method uses lenient validation—if a parameter is incorrect, the model will automatically use the default value without raising an error.

:::
**New method (Recommended): Pass the paramters directly** **in the request body**

```JSON
... 
   // Specify the aspect ratio of the generated video to 16:9, duration to 5 seconds, resolution to 720p, seed to 11, and include a watermark. The camera is not fixed. 
    "model": "seedance-1-5-pro-251215", 
    "content": [ 
        { 
            "type": "text", 
            "text": "The kitten is yawning at the camera" 
        } 
    ], 
    // All parameters must be written in full; abbreviations are not supported 
    "resolution": "720p", 
    "ratio":"16:9", 
    "duration": 5, 
    // "frames": 29, Either duration or frames is required 
    "seed": 11, 
    "camera_fixed": false, 
    "watermark": true 
... 
```

**Legacy method: Append \-\-[parameter] after the text prompt**

```JSON
... 
   // Specify the aspect ratio of the generated video to 16:9, duration to 5 seconds, resolution to 720p, seed to 11, and include a watermark. The camera is not fixed. 
    "model": "seedance-1-5-pro-251215", 
    "content": [ 
        { 
            "type": "text", 
            "text": "The kitten is yawning at the camera --rs 720p --rt 16:9 --dur 5 --seed 11 --cf false --wm true"
            // "text": "The kitten is yawning at the camera --resolution 720p --ratio 16:9 --duration 5 --seed 11 --camerafixed false --watermark true"
        } 
    ]
... 
```

---

**resolution** `string`

> For Seedance 1.5 pro、Seedance 1.0 lite，the default value is `720p`.
> For Seedance 1.0 pro&pro\-fast，the default value is `1080p`.

The resolution of the output video. Valid values:

* 480p
* 720p
* 1080p: `Reference image feature are not supported`

---

**ratio ** `string`

> **Text\-to\-Video:**  Default is `16:9` (The default for Seedance 1.5 Pro is adaptive).
> **Image\-to\-Video:**  Default is `adaptive` (The default for the reference image\-to\-video scenario is `16:9`).

The aspect ratio of the output video. Valid values:

* 16:9
* 4:3
* 1:1
* 3:4
* 9:16
* 21:9
* adaptive: Automatically selects the most suitable aspect ratio based on the input (see details below).

:::warning **Instructions for Using adaptive**
When the **adaptive** parameter is enabled, the model will adaptively adjust the video aspect ratio based on the specific video generation scenario. The actual aspect ratio of the generated video can be obtained from the **ratio** field returned by the [Retrieve a video generation task API](https://docs.byteplus.com/en/docs/ModelArk/1521309).

* **Text\-to\-Video Scenario:**  The most suitable aspect ratio is automatically selected based on the input prompt.
* **Image\-to\-Video Scenario:**  The most suitable aspect ratio is automatically selected based on the aspect ratio of the uploaded first frame image.
* The **adaptive** parameter is not supported in the Reference Image\-to\-Video scenario or in Text\-to\-Video scenarios using the Seedance 1.0 series of models.

:::
Corresponding Width and Height Pixel Values for Different Aspect Ratios
Note: When generating a video from an image, if the selected aspect ratio is inconsistent with that of the uploaded image, Ark will crop your image. The cropping will be centered. For detailed rules, please refer to the [Image Cropping Rules](https://docs.byteplus.com/en/docs/ModelArk/1366799#image-cropping-logic).

|**resolution** |**ratio**|Pixel Values ** (width × height)** |Pixel Values ** (width × height)** |\

|                                                                             |      | **Seedance 1.0 Series** | Seedance 1.5 pro |
| --------------------------------------------------------------------------- | ---- | ----------------------------- | ---------------- |
| 480p                                                                        | 16:9 | 864×480                      | 864×496         |
| ^^                                                                          | 4:3  | 736×544                      | 752×560         |
| ^^                                                                          | 1:1  | 640×640                      | 640×640         |
| ^^                                                                          | 3:4  | 544×736                      | 560×752         |
| ^^                                                                          | 9:16 | 480×864                      | 496×864         |
| ^^                                                                          | 21:9 | 960×416                      | 992×432         |
| 720p                                                                        | 16:9 | 1248×704                     | 1280×720        |
| ^^                                                                          | 4:3  | 1120×832                     | 1112×834        |
| ^^                                                                          | 1:1  | 960×960                      | 960×960         |
| ^^                                                                          | 3:4  | 832×1120                     | 834×1112        |
| ^^                                                                          | 9:16 | 704×1248                     | 720×1280        |
| ^^                                                                          | 21:9 | 1504×640                     | 1470×630        |
| 1080p                                                                       | 16:9 | 1920×1088                    | 1920×1080       |
| >**Seedance 1.0 lite:**  Does not support reference image generation. |      |                               |                  |
| ^^                                                                          | 4:3  | 1664×1248                    | 1664×1248       |
| ^^                                                                          | 1:1  | 1440×1440                    | 1440×1440       |
| ^^                                                                          | 3:4  | 1248×1664                    | 1248×1664       |
| ^^                                                                          | 9:16 | 1088×1920                    | 1080×1920       |
| ^^                                                                          | 21:9 | 2176×928                     | 2206×946        |

---

**duration** `integer` `Default value: 5`

> **Choose either duration or frames; frames takes priority over duration. ** If you want to generate a video of an integer number of seconds, it is recommended to specify **duration**.

The duration of the output video. Unit: seconds.

* Value range: 2~12 s

:::warning warning
**Seedance 1.5 pro** supports two methods for configuring video duration:

* **Specify a fixed duration**: You may set any integer value within the range  **[4, 12]**  (in seconds).
* **Let the model decide**: Set the duration to `-1`, and the model will autonomously select an appropriate video length (in whole seconds) within the  **[4, 12]**  range. The actual generated video duration can be obtained from the **duration** field returned by the  [Retrieve a video generation task API](https://docs.byteplus.com/en/docs/ModelArk/1521309). Please note that video duration is related to billing, so configure this setting carefully.

:::
---

**frames** `Integer`

> Seedance 1.5 pro is not supported.
> **Choose either duration or frames; frames takes priority over duration. ** If you want to generate a video with a fractional second duration, it is recommended to specify **frames**.

Number of frames for the output video. By specifying the number of frames, you can flexibly control the length of the generated video, including videos with fractional second durations. Due to the value constraints of frames, only a limited number of fractional second durations are supported. You need to calculate the closest number of frames using the formula.

* Calculation formula: **Number of Frames = Duration × Frame Rate (24)** .
* Value range: Supports all integer values within the range [29, 289] that conform to the format **25 + 4n**, where **n** is a positive integer.

For example: If you want to generate a 2.4\-second video, the number of frames would be 2.4 × 24 = 57.6. Since 57.6 is not a valid value for frames, you must select the closest valid value. Calculated using the formula 25 + 4n, the closest valid number of frames is 57, and the actual duration of the generated video will be 57 / 24 = 2.375 seconds.

---

**seed** `integer` `Default value: -1`
The seed, which is an integer that controls the randomness of the output content. Valid values: integers within the range of [\-1, 2^32\-1].
:::warning warning

* If the seed parameter is not specified or is set to \-1, a random number is used.
* Changing the seed value is a way to obtain different outputs for the same request. Using the same seed value for the same request generates similar but not necessarily identical outputs.

:::
---

**camera_fixed** `boolean` `Default value: false`

> The reference\-image\-to\-video is not supported

Specifies whether to fix the camera. Valid values:

* `true`: fixes the camera. The platform appends an instruction to fix the camera to your prompt, but does not guarantee the actual effect.
* `false`: does not fix the camera.

---

**watermark** `boolean` `Default value: false`
Specifies whether to add watermarks to the output video. Valid values:

* `false`: does not add watermarks.
* `true`: adds watermarks.

---

`<span id="L9tzcCyD">`

## Response parameters

> Jump to [Request parameters](#RxN8G2nH)

**id ** `string`
The ID of the video generation task. Only retained for 7 days (calculated from the created at timestamp) and will be automatically deleted upon expiration.
Setting `"draft": true` will generate a task ID for a draft video.
Setting `"draft": false` will generate a task ID for a standard video.
Creating a video generation task is an asynchronous interface. After obtaining the ID, you need to query the status of the video generation task through [Querying the information about a video generation task](https://docs.byteplus.com/en/docs/ModelArk/Querying_the_information_about_a_video_generation_task). When the task is successful, the `video_url` of the generated video will be output.

# Retrieve a video generation task

`GET https://ark.ap-southeast.bytepluses.com/api/v3/contents/generations/tasks/{id}` [Try](https://api.byteplus.com/api-explorer/?action=GetContentsGenerationsTask&groupName=Video%20Generation%20API&serviceCode=ark&version=2024-01-01)
Retrieves the information of a video generation task.

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Try" key="fq9yXaKY"><RenderMd content={`<APILink link="https://api.byteplus.com/api-explorer/?action=GetContentsGenerationsTask&groupName=Video%20Generation%20API&serviceCode=ark&version=2024-01-01" description="API Explorer 您可以通过 API Explorer 在线发起调用，无需关注签名生成过程，快速获取调用结果。"></APILink>
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Authentication" key="3vCxpwty"><RenderMd content={`This interface only supports API Key authentication. Obtain a long\\-term API Key on the [ API Key management](https://console.byteplus.com/ark/region:ark+ap-southeast-1/apiKey?apikey=%7B%7D) page.
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Quick Start" key="AmT6L8NRfI"><RenderMd content={` [ ](#)[Experience Center](https://console.byteplus.com/ark/region:ark+ap-southeast-1/experience/vision?projectName=default)[ ](https://console.byteplus.com/ark/region:ark+ap-southeast-1/experience/vision?projectName=default)[Model List](https://docs.byteplus.com/en/docs/ModelArk/1330310)<span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_a5fdd3028d35cc512a10bd71b982b6eb.png =20x) </span>[Model Billing](https://docs.byteplus.com/en/docs/ModelArk/1099320#video-generation)<span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_afbcf38bdec05c05089d5de5c3fd8fc8.png =20x) </span>[API Key](https://console.byteplus.com/ark/region:ark+ap-southeast-1/apiKey?apikey=%7B%7D)
 <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_57d0bca8e0d122ab1191b40101b5df75.png =20x) </span>[API Call Guide](https://docs.byteplus.com/en/docs/ModelArk/1366799)<span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_f45b5cd5863d1eed3bc3c81b9af54407.png =20x) </span>[API Reference](https://docs.byteplus.com/en/docs/ModelArk/Video_Generation_API)<span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_1609c71a747f84df24be1e6421ce58f0.png =20x) </span>[FAQs](https://docs.byteplus.com/en/docs/ModelArk/1359411)<span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_bef4bc3de3535ee19d0c5d6c37b0ffdd.png =20x) </span>[Model Activation](https://console.byteplus.com/ark/region:ark+ap-southeast-1/openManagement?LLM=%7B%7D&tab=ComputerVision)
`}></RenderMd></Tabs.TabPane></Tabs>);
```

---

`<span id="RxN8G2nH">`

## Request parameters

> See [Response parameters](#7mi8G8RI)

---

`<span id="aN7zwSry">`

### Path parameters

**id** `string` %%require%%
The ID of the video generation task to query.

---

`<span id="7mi8G8RI">`

`<span id="7mi8G8RI">`

## Response parameters

> See [Request parameters](#RxN8G2nH)

---

**id ** `string`
The ID of the video generation task.

---

**model** `string`
The name and version of the model used by the task (`Model name-Version`)

---

**status** `string`
The status of the task. Valid values:

* `queued`
* `running`
* `cancelled` (Only tasks in the queued state can be canceled)
* `succeeded`
* `failed`
* `expired`

---

* **error** `object / null`

The error information. If the task succeeds, `null` is returned. If the task fails, the error information is returned. For more information, refer to [Error codes](https://docs.byteplus.com/en/docs/ModelArk/1299023).

Attributes

---

error.**code** `string`
The error code.

---

error.**message** `string`
The error message.

---

**created_at** `integer`
The time when the task was created. The value is a Unix timestamp in seconds.

---

**updated_at** `integer`
The time when the task was last updated. The value is a Unix timestamp in seconds.

---

**content** `object`
The output after the video generation task is completed.

Attributes

---

content.**video_url** `string`
The URL of the output video. For security purposes, the output video is deleted after 24 hours. Be sure to save it in time.

---

content.**last_frame_url ** `string`
URL of the last frame of the generated video. Valid for 24 hours. Be sure to save it in time.
Note：If you set `"return_last_frame": true` in the [creating a video generation task](https://docs.byteplus.com/en/docs/ModelArk/1520757) request, the parameter will be returned.

---

**seed** `integer`
The seed value (integer) used for this request.

---

**resolution **  `string`
The resolution of the generated video.

---

**ratio ** `string`
The width\-to\-height ratio of the generated video.

---

**duration** `integer`
The length of the generated video in seconds.
**Note: ** Only one of the **duration** and **frames** parameters is returned. If **frames** is not specified in the creating video generation request, **duration** will be returned.

---

**frames** `integer`
Number of frames for the generated video.
**Note: ** Only one of the **duration** and **frames** parameters will be returned. If **frames** is specified in the creating video generation request, **frames** will be returned.

---

**framespersecond**  `integer`
The frame rate of the generated video.

---

**generate_audio==^new^==** `boolean`
Whether the generated video includes audio synchronized with the visuals. This parameter is **only supported by Seedance 1.5 pro**.

* **true**: The model outputs a video with synchronized audio.
* **false**: The model outputs a silent video.

---

**draft==^new^==** `boolean`
Whether the generated video is a Draft video. This parameter is only returned by Seedance 1.5 Pro.

* **true**: The current output is a Draft video.
* **false**: The current output is a standard video.

---

**draft_task_id==^new^==** ** ** `string`
Draft video task ID. This parameter will be returned when generating an official video based on a Draft video.

---

**service_tier ** `string`
The service tier actually used to process the task.

---

**execution_expires_after ** `integer`
The expiration threshold for the task, in seconds.

---

**usage** `object`
The token usage for the request.

Attributes

---

usage.**completion_tokens** `integer`
The number of tokens consumed for the video output by the model.

---

usage.**total_tokens** `integer`
Total tokens for this request. For video models, input tokens are always 0, therefore **total_tokens = completion_tokens**.

# List video generation tasks

`GET https://ark.ap-southeast.bytepluses.com/api/v3/contents/generations/tasks?page_num={page_num}&page_size={page_size}&filter.status={filter.status}&filter.task_ids={filter.task_ids}&filter.model={filter.model}`    [Try](https://api.byteplus.com/api-explorer/?action=ListContentsGenerationsTasks&groupName=Video%20Generation%20API&serviceCode=ark&version=2024-01-01)
You can specify the filter parameters to retrieve a list of tasks.
:::tip Instructions
Only the historical data from the past **7 days** can be queried. Time calculation is based on UTC timestamps. The 7\-day range is determined using the exact moment (to the second) when the batch query request is made, with the time window defined as  **[T − 7 days, T)** .

:::

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Quick start" key="opV4RT2k"><RenderMd content={` [ ](#)[Experience Center](https://console.byteplus.com/ark/region:ark+ap-southeast-1/experience/vision?projectName=default)[ ](https://console.byteplus.com/ark/region:ark+ap-southeast-1/experience/vision?projectName=default)[Model List](https://docs.byteplus.com/en/docs/ModelArk/1330310)<span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_a5fdd3028d35cc512a10bd71b982b6eb.png =20x) </span>[Model Billing](https://docs.byteplus.com/en/docs/ModelArk/1099320#video-generation)<span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_afbcf38bdec05c05089d5de5c3fd8fc8.png =20x) </span>[API Key](https://console.byteplus.com/ark/region:ark+ap-southeast-1/apiKey?apikey=%7B%7D)
 <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_57d0bca8e0d122ab1191b40101b5df75.png =20x) </span>[API Call Guide](https://docs.byteplus.com/en/docs/ModelArk/1366799)<span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_f45b5cd5863d1eed3bc3c81b9af54407.png =20x) </span>[API Reference](https://docs.byteplus.com/en/docs/ModelArk/Video_Generation_API)<span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_1609c71a747f84df24be1e6421ce58f0.png =20x) </span>[FAQs](https://docs.byteplus.com/en/docs/ModelArk/1359411)<span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_bef4bc3de3535ee19d0c5d6c37b0ffdd.png =20x) </span>[Model Activation](https://console.byteplus.com/ark/region:ark+ap-southeast-1/openManagement?LLM=%7B%7D&tab=ComputerVision)
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Authentication" key="CPeW5vNl"><RenderMd content={`This interface only supports API Key authentication. Obtain a long\\-term API Key on the [ API Key management](https://console.byteplus.com/ark/region:ark+ap-southeast-1/apiKey?apikey=%7B%7D) page.
`}></RenderMd></Tabs.TabPane></Tabs>);
```

---

`<span id="RxN8G2nH">`

## Request parameters

> See [Response parameters](#7mi8G8RI)

&nbsp;
`<span id="wRGjj9E7">`

### Query parameters

---

**page_num** `integer / null`
The page number of the returned results.

* Valid values: [1, 500]

---

**page_size ** `integer / null`
The number of entries per page.

* Valid values: [1, 500]

---

**filter.status ** `string / null`
The status of the task. Valid values:

* `queued`
* `running`
* `cancelled` (Only tasks in the queued state can be canceled)
* `succeeded`
* `failed`

---

**filter.task_ids ** `string[] / null`
Search for specific video generation tasks using the task ID. Multiple IDs can be passed, separated with `&`.
Example：`filter.task_ids=id1&filter.task_ids=id2`.

---

**filter.model ** `string / null`
The ID of the used inference endpoint for the exact search, which differs from the model parameter in the response.

---

**filter.service_tier==^new^==** ** ** `string / null` `Default value: default`
The service tier to process tasks.

* `default`: Online inference mode.
* `flex`: Offline inference mode.

`<span id="7mi8G8RI">`

## Response parameters

> See [Request parameters](#RxN8G2nH)

---

**items ** `object[]`
The retrieved video generation tasks.

Attributes

---

items.**id ** `string`
The ID of the video generation task.

---

items.**model** `string`
The name and version of the model used by the task (`Model name-Version`).

---

items.**status** `string`
The state of the task. Valid values:

* `queued`
* `running`
* `cancelled` (The task has been canceled. Only tasks in the queued state can be canceled.)
* `succeeded`
* `failed`
* `expired`**==^new^==**

---

items.**error** `object / null`
The error information. If the task succeeds, `null` is returned. If the task fails, the error information is returned. For more information, refer to [Error codes](https://docs.byteplus.com/en/docs/ModelArk/1299023).

Attributes

---

error.**code** `string`
The error code.

---

error.**message** `string`
The error message.

---

items.**created_at** `integer`
The time when the task was created. The value is a UNIX timestamp in seconds.

---

items.**updated_at** `integer`
The time when the task was last updated. The value is a UNIX timestamp in seconds.

---

items.**content** `object`
The output of the video generation task. It contains the download URL of the output video.

Attributes

---

content.**video_url** `string`
The URL of the output video. For security purposes, the output video is cleared after 24 hours. Save it in time.

---

content.**last_frame_url ** `string`
URL of the Video's last frame. Valid for 24 hours. Be sure to save it in time.
Note：When setting `"return_last_frame": true` in the [creating a video generation task](https://docs.byteplus.com/en/docs/ModelArk/1520757) request, the parameter will be returned.

---

items.**seed** `integer`
The integer value used for this generation task.

---

items.**resolution **  `string`
The resolution of the generated video.

---

items.**ratio ** `string`
The width\-to\-height ratio of the generated video.

---

items.**duration** `integer`
The length of the generated video in seconds.
**Note: ** Only one of the **duration** and **frames** parameters will be returned. If **frames** is not specified when creating a video generation task, **duration** will be returned.

---

items.**frames** `integer`
The number of frames of the generated video.
**Note: ** Only one of the **duration** and **frames** parameters will be returned. If **frames** is specified when creating a video generation, **frames** will be returned.

---

items.**framespersecond**  `integer`
The frame rate of the generated video.

---

items.**generate_audio==^new^==** `boolean`
Wwhether the generated video includes audio synchronized with the visuals. This parameter is **only supported by Seedance 1.5 pro**.

* `true`: The model outputs a video with synchronized audio.
* `false`: The model outputs a silent video.

---

items.**draft==^new^==** `boolean`
Whether the generated video is a Draft video. This parameter is only returned by Seedance 1.5 Pro.

* `true`: The current output is a Draft video.
* `false`: The current output is a standard video.

---

items.**draft_task_id==^new^==**`string`
Draft video task ID. This parameter will be returned when generating an official video based on a Draft video.

---

items.**service_tier ** `string`
The actual service tier used to process the task.

---

items.**execution_expires_after ** `integer`
The expiration threshold for the task, in seconds.

---

items.**usage** `object`
The token usage for the request.

Attributes

---

usage.**completion_tokens** `integer`
The number of tokens consumed for the video output by the model.

---

usage.**total_tokens** `integer`
Total tokens for this request. For video models, input tokens are always 0, therefore **total_tokens = completion_tokens**.

---

**total ** `integer`
The number of tasks that match the filter conditions.

# Cancel or delete a video generation task

`DELETE https://ark.ap-southeast.bytepluses.com/api/v3/contents/generations/tasks/{id}`  [Try](https://api.byteplus.com/api-explorer/?action=DeleteContentsGenerationsTasks&groupName=Video%20Generation%20API&serviceCode=ark&version=2024-01-01)
Cancels a queued video generation task, or deletes a video generation task record.

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Try" key="vI631gwS"><RenderMd content={`<APILink link="https://api.byteplus.com/api-explorer/?action=DeleteContentsGenerationsTasks&groupName=Video%20Generation%20API&serviceCode=ark&version=2024-01-01" description="API Explorer 您可以通过 API Explorer 在线发起调用，无需关注签名生成过程，快速获取调用结果。"></APILink>
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Authentication" key="L8aMwmZD"><RenderMd content={`This interface only supports API Key authentication. Obtain a long\\-term API Key on the [ API Key management](https://console.byteplus.com/ark/region:ark+ap-southeast-1/apiKey?apikey=%7B%7D) page.
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Quick start" key="e1XZwU7pkX"><RenderMd content={` [ ](#)[Experience Center](https://console.byteplus.com/ark/region:ark+ap-southeast-1/experience/vision?projectName=default)[ ](https://console.byteplus.com/ark/region:ark+ap-southeast-1/experience/vision?projectName=default)[Model List](https://docs.byteplus.com/en/docs/ModelArk/1330310)<span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_a5fdd3028d35cc512a10bd71b982b6eb.png =20x) </span>[Model Billing](https://docs.byteplus.com/en/docs/ModelArk/1099320#video-generation)<span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_afbcf38bdec05c05089d5de5c3fd8fc8.png =20x) </span>[API Key](https://console.byteplus.com/ark/region:ark+ap-southeast-1/apiKey?apikey=%7B%7D)
 <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_57d0bca8e0d122ab1191b40101b5df75.png =20x) </span>[API Call Guide](https://docs.byteplus.com/en/docs/ModelArk/1366799)<span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_f45b5cd5863d1eed3bc3c81b9af54407.png =20x) </span>[API Reference](https://docs.byteplus.com/en/docs/ModelArk/Video_Generation_API)<span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_1609c71a747f84df24be1e6421ce58f0.png =20x) </span>[FAQs](https://docs.byteplus.com/en/docs/ModelArk/1359411)<span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_bef4bc3de3535ee19d0c5d6c37b0ffdd.png =20x) </span>[Model Activation](https://console.byteplus.com/ark/region:ark+ap-southeast-1/openManagement?LLM=%7B%7D&tab=ComputerVision)
`}></RenderMd></Tabs.TabPane></Tabs>);
```

---

`<span id="RxN8G2nH">`

## Request parameters

> See [Response parameters](#7mi8G8RI)

&nbsp;
`<span id="k1empPqb">`

### Path parameters

**id** `string` `required`
The ID of the video generation task to be canceled or deleted.
The operation performed by the `DELETE` API varies depending on the status of the video generation task:

| **Task Status** | **Can it be deleted?** | **Operation Description**                                              | **Post\-DELETE Task Status** |
| --------------------- | ---------------------------- | ---------------------------------------------------------------------------- | ---------------------------------- |
| queued                | Yes                          | The task is removed from the queue and its status is updated to 'cancelled'. | cancelled                          |
| running               | No                           | \-                                                                           | \-                                 |
| succeeded             | Yes                          | The video generation task record is deleted and will no longer be queryable. | \-                                 |
| failed                | Yes                          | The video generation task record is deleted and will no longer be queryable. | \-                                 |
| cancelled             | No                           | \-                                                                           | \-                                 |
| expired               | Yes                          | The video generation task record is deleted and will no longer be queryable. | \-                                 |

---

&nbsp;
`<span id="7mi8G8RI">`

## Response parameters

> See [Request parameters](#RxN8G2nH)

This API operation has no response parameters.
